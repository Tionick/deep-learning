{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nicolas Leguizamon Taller 9. Aprendizaje profundo con TensorFlow \n",
    "\n",
    "Hasya ahora, se ha venido utilizando numpy para construir las redes neuronales profundas. Ahora va a utilizar un paquete especialmente diseñado para implementar las funciones que ha venido implementando paso a paso, bajo un marco de **deep learning** que le permite construir redes nueronales más fácilmente. Hay distintos ejemplos de paquetes abiertos que pueden ser utilizados para el aprendizaje computacional, como por ejemplo TensorFlow, PaddlePaddle, Torch, Caffe, Keras, entre otros, que pueden ser utilizados para su desarrollo de sus proyectos en aprendizaje computacional. Estas bibliotecas pueden acortar los tiempos de desarrollo y programación, junto con una implementación más eficiente de los distintos algoritmos de optimización). \n",
    "\n",
    "Aquí vamos a estudiar la biblioteca TensorFlow: \n",
    "\n",
    "- Inicialización de parámetros\n",
    "- Empezar la sesión\n",
    "- Entrenar algoritmos \n",
    "- Implementar una red neuronal\n",
    "\n",
    "\n",
    "## 1 - Explorando la biblioteca Tensorflow \n",
    "\n",
    "Ejecutando la siguiente celda puede importar la biblioteca:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicolas L\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola, soy una constante que has definido el ambiente TensorFlow!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant('Hola, soy una constante que has definido el ambiente TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello).decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Primero hagamos un recorrido por la biblioteca. Por ejemplo, calculemos la pérdida sobre un ejemplo/patrón dado (36,39).  \n",
    "$$pérdida = \\mathcal{L}(\\hat{y}, y) = (\\hat y^{(i)} - y^{(i)})^2 \\tag{1}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La pérdida es de: 9\n"
     ]
    }
   ],
   "source": [
    "y_est = tf.constant(36, name='y_est')            # Define una constante y_est = 36.\n",
    "y = tf.constant(39, name='y')                    # Define y = 39\n",
    "\n",
    "loss = tf.Variable((y - y_est)**2)               # Crea una variable para la pérdida = loss\n",
    "\n",
    "init = tf.global_variables_initializer()         # Cuando se ejecute init (en session.run(init)), la variable loss será incializada\n",
    "                                                 # y lista a ser computada\n",
    "with tf.Session() as session:                    # Crea una sesión e imprime la salida\n",
    "    session.run(init)                            # Inicializa la variables\n",
    "    print('La pérdida es de:',session.run(loss)) # Imprime la pérdida = 3^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los pasos que hay que seguir para programar en TensorFlow:\n",
    "\n",
    "1. Crear **tensores** (variables) antes de ejecutarlos. \n",
    "2. Programar las operaciones entre los tensores.\n",
    "3. Incializar los tensores. \n",
    "4. Crear una sesión \"Session\". \n",
    "5. Ejecutar la sesión con las operaciones que se deben programar. \n",
    "\n",
    "De esta manera, la variable \"loss\" se definió como una función de otras cantidades, mediante `init=tf.global_variables_initializer()`. Esta función inicializó la variable de pérdida \"loss\", hasta que finalmente se evalúa y se imprime su valor. \n",
    "\n",
    "Ahora, veamos la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mul_1:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(2)\n",
    "b = tf.constant(10)\n",
    "c = tf.multiply(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Esperaba que la respuesta fuera 20? Nótese que lo que se obtuvo fue un tensor diciendo que el resultado es un tensor que no tiene forma (dimensión), y es de tipo \"int32\". En este sentido, hasta ahora todo lo que ha hecho es definir el ´grafo computacional', pero el comando no se ha ejecutado aún. Para multiplicar los dos números, debe crear la sesión y ejecutarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Recuerde:**\n",
    "\n",
    "- Hay que inicializar las variables, crear una sesión y ejecutar las operaciones dentro de la sesión. \n",
    "\n",
    "- Paso siguiente, debe declarar unos 'placeholders' (ó handles). Estos placeholders son son objetos cuyo valor sólo puede ser especificado después.  \n",
    "\n",
    "Para especificar los valores de un placeholder, puede asignarle valores utilizando un diccionario de entrada (variable `feed_dict`). \n",
    "        \n",
    "\n",
    "En la siguiente celda se ha creado un placeholder para x. De esta manera se le puede pasar un valor numérico tras ejecutar la sesión. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Cambia el valor de x en el feed_dict\n",
    "\n",
    "x = tf.placeholder(tf.int64, name = 'x')\n",
    "print(sess.run(2 * x, feed_dict = {x: 3}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fíjese que cuando definió por primera vez `x`, no tuvo que especificar su valor. Un placeholder es simplemente una variable a la cual se le va a asignar un valor más adelante, cuando se ejecute la sesión. De este modo, al ejecutar la sesión es que se le pasa su valor. \n",
    "\n",
    "Lo que está pasando, cuando se especifican las operaciones requeridas para la computación, se le está diciendo a TensorFlow cómo contruir el grafo computacional. Este grafo va a tener algunos placeholders a los que se les asignará un valor después. Cuando se ejecute la sesión, se le está diciendo a TensorFlow que ejecute el grafo computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Función lineal\n",
    "\n",
    "Este primer ejercicio consiste en computar la siguiente ecuación: $Y = WX + b$, donde $W$ y $X$ son matrices aleatorias y b es un vector aleatorio. \n",
    "\n",
    "**Ejercicio**: Compute $WX + b$ donde $W, X$, y $b$ son tomados de una distribución Normal. W es de tamaño (4, 3), X es de (3,1) y b es de (4,1). Por ejemplo, una constante X de dimensiones (3,1) se definiría:\n",
    "```python\n",
    "X = tf.constant(np.random.randn(3,1), name = \"X\")\n",
    "\n",
    "```\n",
    "Las siguientes funciones pueden ser de ayuda: \n",
    "- tf.matmul(..., ...) para multiplicación entre matrices\n",
    "- tf.add(..., ...) para suma\n",
    "- np.random.randn(...) para inicialización aleatoria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: linear_function\n",
    "\n",
    "def linear_function():\n",
    "    \"\"\"\n",
    "    Implementa una función lineal: \n",
    "            Inicializa W como un tensor aleatorio de tamaño (4,3)\n",
    "            Inicializa X como un tensor aleatorio de tamaño (3,1)\n",
    "            Inicializa b como un tensor aleatorio de tamaño (4,1)\n",
    "    Output: \n",
    "    result: ejecuta la sesión para Y = WX + b \n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ###  (≈ 4 líneas de código)\n",
    "    X = tf.constant(np.random.randn(3, 1), name=\"X\")\n",
    "    W = tf.constant(np.random.randn(4, 3), name=\"W\")\n",
    "    b = tf.constant(np.random.randn(4, 1), name=\"b\")\n",
    "    Y = tf.add(tf.matmul(W, X), b)\n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    # Empieze la sesión usando tf.Session() y ejecútela con sess.run(...) sobre la variable que quiera calcular\n",
    "    \n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### \n",
    "    sess = tf.Session()\n",
    "    result = sess.run(Y)\n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    # Cierre la sesión\n",
    "    sess.close()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultado = [[-2.15657382]\n",
      " [ 2.95891446]\n",
      " [-1.08926781]\n",
      " [-0.84538042]]\n"
     ]
    }
   ],
   "source": [
    "print( \"resultado = \" + str(linear_function()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**:\n",
    "\n",
    "<table> \n",
    "<tr> \n",
    "<td>\n",
    "**resultado**\n",
    "</td>\n",
    "<td>\n",
    "[[-2.15657382]\n",
    " [ 2.95891446]\n",
    " [-1.08926781]\n",
    " [-0.84538042]]\n",
    "</td>\n",
    "</tr> \n",
    "\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Computación del sigmoide \n",
    "Acaba de implementar una función lineal. Tensorflow ofrece una variedad de funciones que suelen utilizarse con redes neuronales como e.g. `tf.sigmoid` y `tf.softmax`. Para este ejercicio compute el sigmoide de un input. \n",
    "\n",
    "Este ejercicio consiste en utilizar una variable placeholder `x`, para que al ejecutar la sesión, utilize el diccionario de entrada para pasar los valores de `z`. Por lo tanto, (i) defina el placeholder `x`, (ii) defina las operaciones requeridas para computar el sigmoide usando `tf.sigmoid`, y finalmente, (iii) ejecute la sesión. \n",
    "\n",
    "** Ejercicio **: Implemente la función sigmoide usando las siguientes funciones: \n",
    "\n",
    "- `tf.placeholder(tf.float32, name = \"...\")`\n",
    "- `tf.sigmoid(...)`\n",
    "- `sess.run(..., feed_dict = {x: z})`\n",
    "\n",
    "\n",
    "Nótese que hay dos manera en las que usualmente se empieza y ejecutan las sesiones en tensorflow: \n",
    "\n",
    "**Modo 1:**\n",
    "```python\n",
    "sess = tf.Session()  # empieza la sesión\n",
    "result = sess.run(..., feed_dict = {...})\n",
    "sess.close() # termina la sesión\n",
    "```\n",
    "**Modo 2:**\n",
    "```python\n",
    "with tf.Session() as sess: \n",
    "    result = sess.run(..., feed_dict = {...})\n",
    "    # se cierra automáticamente\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: sigmoid\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Calcula el sigmoide de z\n",
    "    Input:\n",
    "    z: valor de entrada\n",
    "    Output:\n",
    "    results: sigmoide de z\n",
    "    \"\"\"\n",
    "    \n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ###  (≈ 4 líneas de código)\n",
    "    # Crear el placeholder para x. Nombrarlo 'x'.\n",
    "    x = tf.placeholder(tf.float32, name=\"x\")\n",
    "\n",
    "    # compute sigmoide(x)\n",
    "    sigmoid = tf.sigmoid(x)\n",
    "\n",
    "    # Empiece una sesión, y ejecútela. Utilize el Modo 2 descrito arriba. \n",
    "    # Debe utilizar el feed_dict para pasar el valor de z a x. \n",
    "    with tf.Session() as sess: \n",
    "    # Ejecute la sesión y llame a la salida \"result\"\n",
    "        result = sess.run(sigmoid, feed_dict={x: z})\n",
    "    \n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoide(0) = 0.5\n",
      "sigmoide(12) = 0.9999938\n"
     ]
    }
   ],
   "source": [
    "print (\"sigmoide(0) = \" + str(sigmoid(0)))\n",
    "print (\"sigmoide(12) = \" + str(sigmoid(12)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**:\n",
    "\n",
    "<table> \n",
    "<tr> \n",
    "<td>\n",
    "**sigmoide(0)**\n",
    "</td>\n",
    "<td>\n",
    "0.5\n",
    "</td>\n",
    "</tr>\n",
    "<tr> \n",
    "<td>\n",
    "**sigmoide(12)**\n",
    "</td>\n",
    "<td>\n",
    "0.999994\n",
    "</td>\n",
    "</tr> \n",
    "\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "**Lo que debe haber aprendido**:\n",
    "1. Crear placeholders\n",
    "2. Especificar el grafo computacional para las operaciones que busca computar\n",
    "3. Crear una sesión\n",
    "4. Ejecutar la sesión, usando un diccionario de entrada (feed-dict), y si es necesario especificar los valores de las variables placeholder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 -  Computar la pérdida\n",
    "\n",
    "También se puede usar una función ya especificada para computar la pérdida de la red neuronal. De esta manera, en lugar de tener que programar la función de $a^{[2](i)}$ y $y^{(i)}$ para i=1...m: \n",
    "$$ J = - \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log a^{ [2] (i)} + (1-y^{(i)})\\log (1-a^{ [2] (i)} )\\large )\\small\\tag{2}$$\n",
    "\n",
    "se puede hacer lo mismo en una línea de código en tensorflow.\n",
    "\n",
    "**Ejercicio**: Implemente la función de pérdida de entropía cruzada, mediante la función: \n",
    "\n",
    "\n",
    "- `tf.nn.sigmoid_cross_entropy_with_logits(logits = ...,  labels = ...)`\n",
    "\n",
    "Su código debe recibir `z`, computar el sigmoide (para obtener `a`) y luego computar la pérdida de entropía cruzada $J$. Esto se puede hacer llamando a `tf.nn.sigmoid_cross_entropy_with_logits`, el cual computa\n",
    "\n",
    "$$- \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log \\sigma(z^{[2](i)}) + (1-y^{(i)})\\log (1-\\sigma(z^{[2](i)})\\large )\\small\\tag{2}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: cost\n",
    "\n",
    "def cost(logits, labels):\n",
    "    \"\"\"\n",
    "    Computa el coste usando entropía cruzada sigmoide\n",
    "    Input:\n",
    "    logits: vector conteniendo z (\"logits\"), la salida de la última unidad lineal (antes de la activación final sigmoide)\n",
    "    labels: vector de etiquetas y (\"labels\", 1 ó 0) \n",
    "    Salida:\n",
    "    cost: ejecuta la sesión del coste (formula (2))\n",
    "    \"\"\"\n",
    "    \n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ###  \n",
    "    \n",
    "    # Declare los placeholders para \"logits\" (z) y \"labels\" (y) (≈ 2 líneas de código)\n",
    "    z = tf.placeholder(tf.float32, name=\"z\")\n",
    "    y = tf.placeholder(tf.float32, name=\"y\")\n",
    "    \n",
    "    # Use la función de pérdida (≈ 1 línea de código)\n",
    "    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=z, labels=y)\n",
    "    \n",
    "    # Empiece la sesión (≈ 1 línea de código). Según el Modo 1.\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Ejecute la sesión (≈ 1 línea de código).\n",
    "    cost = sess.run(cost, feed_dict={z: logits, y: labels})\n",
    "    \n",
    "    # Cierre la sesión (≈ 1 línea de código). \n",
    "                       # Termine la sesión\n",
    "    \n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coste = [1.0053872  1.0366408  0.41385433 0.39956617]\n"
     ]
    }
   ],
   "source": [
    "logits = sigmoid(np.array([0.2,0.4,0.7,0.9]))\n",
    "cost = cost(logits, np.array([0,0,1,1]))\n",
    "print (\"coste = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**:\n",
    "\n",
    "<table> \n",
    "    <tr> \n",
    "        <td>\n",
    "            **coste**\n",
    "        </td>\n",
    "        <td>\n",
    "        [ 1.00538719  1.03664088  0.41385433  0.39956614]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 - Codificación de etiquetas de unos\n",
    "\n",
    "Muchas veces en problemas de estimación con aprendizaje computacional o deep learning, puede haber un vector y con valores que vayan de 0 a C-1, donde C es el número de clases. Si C es por ejemplo 3, entonces se puede tener un vector y=(2,1,0,1), donde el primer ejemplo es de la clase 2, el segundo de la 1, el tercero de la 0, y el cuarto de la 1. Esta información se puede codificar de la siguiente manera:\n",
    "\n",
    "$$ Y = \\begin{bmatrix}\n",
    "    0  & 0  & 1 & 0 \\\\\n",
    "    0  & 1 & 0  & 1\\\\\n",
    "    1  & 0 & 0 & 0 \n",
    "\\end{bmatrix}\\;\\;\\; $$\n",
    "\n",
    "A esto se le suele llamar una codificación \"one hot\", porque en la nueva codificación hay exactamente un elemento de cada vector columna que es positivo (igual a 1) o que está \"caliente\" (ó \"hot\"). Para hacer esta conversión en numpy, puede tomar algunas líneas de código. En tensorflow, se puede hacer en una línea: \n",
    "\n",
    "- tf.one_hot(labels, depth, axis) \n",
    "\n",
    "**Ejercicio:** Implemente la función abajo para tomar un vector de etiquetas y el número total de clases $C$, y devolver la nueva codificación. Para hacerlo utilice `tf.one_hot()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: one_hot_matrix\n",
    "\n",
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Crea una matriz donde la i-ésima fila corresponde con la i-ésima clase de la j-ésima columna (j-ésimo ejemplo de entrenamiento)\n",
    "    Input:    \n",
    "    labels: vector con las etiquetas \n",
    "    C: número de clases\n",
    "    Output:\n",
    "    one_hot: matriz con la codificación one hot\n",
    "    \"\"\"\n",
    "    \n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### \n",
    "    \n",
    "    # Declare una tf.constant igual a C (depth), y nómbrela 'C'. (≈ 1 línea de código)\n",
    "    C = tf.constant(C, name=\"C\")\n",
    "    \n",
    "    # Use tf.one_hot, recuerde especificar el eje (\"axis\") (≈ 1 línea de código)\n",
    "    one_hot_matrix = tf.one_hot(labels, C, axis=0)\n",
    "    \n",
    "    # Empieze la sesión (≈ 1 línea de código)\n",
    "    sess =  tf.Session()\n",
    "    \n",
    "    # Ejecute la sesión (≈ 1 línea de código)\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    # Cierre la sesión (≈ 1 línea de código). \n",
    "             # Termine la sesión\n",
    "    \n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot = [[0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "labels = np.array([1,2,3,0,2,1])\n",
    "one_hot = one_hot_matrix(labels, C = 4)\n",
    "print (\"one_hot = \" + str(one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**:\n",
    "\n",
    "<table> \n",
    "    <tr> \n",
    "        <td>\n",
    "            **one_hot**\n",
    "        </td>\n",
    "        <td>\n",
    "        [[ 0.  0.  0.  1.  0.  0.]\n",
    " [ 1.  0.  0.  0.  0.  1.]\n",
    " [ 0.  1.  0.  0.  1.  0.]\n",
    " [ 0.  0.  1.  0.  0.  0.]]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 - Inicialización con ceros y unos\n",
    "\n",
    "Ahora va a inicializar un vector con ceros y unos. La función que debe utilizar para inicializar con unos es `tf.ones()`. Para inicializar con ceros puede usar tf.zeros(). Estas funciones reciben las dimensiones y devuelven un arreglo de las dimensiones especificadas de unos  o ceros. \n",
    "\n",
    "**Ejercicio:** Implemente la función abajo que tome unas dimensiones y devuelva un arreglo con esas dimensiones de unos. Utilice: \n",
    " - tf.ones(shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: ones\n",
    "\n",
    "def ones(shape):\n",
    "    \"\"\"\n",
    "    Crea un arreglo de unos de dimensión \"shape\"\n",
    "    Input:\n",
    "    shape: dimensiones del arreglo que se quiere crear\n",
    "    Output:\n",
    "    ones: arreglo de unos\n",
    "    \"\"\"\n",
    "    \n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### \n",
    "    \n",
    "    # Crea un tensor de \"unos\" usando tf.ones(...). (≈ 1 línea de código)\n",
    "    ones = tf.ones(shape)\n",
    "    \n",
    "    # Empieza la sesión (≈ 1 línea de código)\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Ejecuta la sesión para computar 'ones' (≈ 1 línea de código)\n",
    "    ones = sess.run(ones)\n",
    "    \n",
    "    # Cierra la sesión (≈ 1 línea de código). \n",
    "             # Termine la sesión\n",
    "    \n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    return ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unos = [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print (\"unos = \" + str(ones([3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**:\n",
    "\n",
    "<table> \n",
    "    <tr> \n",
    "        <td>\n",
    "            **unos**\n",
    "        </td>\n",
    "        <td>\n",
    "        [ 1.  1.  1.]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Desarrollo de una red neuronal en tensorflow\n",
    "\n",
    "En esta parte del taller va a construir una red neuronal usando tensorflow. Recuerde que hay dos partes que debe implementar en tensorflow:\n",
    "\n",
    "- Crear el grafo computacional\n",
    "- Ejecutar el grafo\n",
    "\n",
    "\n",
    "### 2.0 - Enunciado del problema: Identificación de signos\n",
    "\n",
    "El propósito es el de identificar lenguage de signos. En primera instancia, el problema se simplifica para consturir un modelo de red neuronal que facilite la comunicación por signos para cantidades de 0 a 5.\n",
    "\n",
    "- **Conjunto de entrenamiento**: 1080 imagenes (de 64 x 64 pixeles) de signos representando números de 0 a 5 (180 imagenes por número).\n",
    "- **Conjunto de prueba**: 120 imagenes (de 64 x 64 pixeles) de signos representando números de 0 a 5 (20 imágenes por número).\n",
    "\n",
    "\n",
    "Ejecute el siguiente código para cargar el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore los ejemplos del conjunto de datos por medio del índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x000002AC2D7BFF28>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nicolas L\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 704, in __del__\n",
      "    if self._session is not None:\n",
      "AttributeError: 'Session' object has no attribute '_session'\n",
      "Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x000002AC2D728A20>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nicolas L\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 704, in __del__\n",
      "    if self._session is not None:\n",
      "AttributeError: 'Session' object has no attribute '_session'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMj1wD2YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ac2da139e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ejemplo de una imagen\n",
    "index = 16\n",
    "plt.imshow(X_train_orig[index])\n",
    "print (\"y = \" + str(np.squeeze(Y_train_orig[:, index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es usual, se debe aplanar el conjunto de datos, y luego normalizar dividiendo por 255. Además, cada etiqueta se debe re-codificar a un vector one-hot. Ejecute la celda abajo para hacerlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de ejemplos de entrenamiento = 1080\n",
      "Número de ejemplos de prueba = 120\n",
      "Tamaño de X_train: (12288, 1080)\n",
      "Tamaño de Y_train: (6, 1080)\n",
      "Tamaño de X_test: (12288, 120)\n",
      "Tamaño de Y_test: (6, 120)\n"
     ]
    }
   ],
   "source": [
    "# Aplana la imagenes\n",
    "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
    "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
    "\n",
    "# Normaliza los datos\n",
    "X_train = X_train_flatten/255.\n",
    "X_test = X_test_flatten/255.\n",
    "\n",
    "# Convierte las etiquetas a matrices one-hot\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6)\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6)\n",
    "\n",
    "print (\"Número de ejemplos de entrenamiento = \" + str(X_train.shape[1]))\n",
    "print (\"Número de ejemplos de prueba = \" + str(X_test.shape[1]))\n",
    "print (\"Tamaño de X_train: \" + str(X_train.shape))\n",
    "print (\"Tamaño de Y_train: \" + str(Y_train.shape))\n",
    "print (\"Tamaño de X_test: \" + str(X_test.shape))\n",
    "print (\"Tamaño de Y_test: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fíjese que el 12288 obedece a que $64 \\times 64 \\times 3 = 12288$. Cada imagen es cuadrada, de 64 x 64 pixeles, y el 3 es por los canales RGB. Asegúrese de entender las dimensiones de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo:** \n",
    "Construir un modelo que reconozca un signo con buena precisión. Para hacerlo, construya un modelo de tensorflow que va a seguir la misma estructura de los modelos que ya ha implementado antes para el reconocimiento de gatos, pero utilizando una capa de salida softmax. Así puede comparar los resultados obtenidos con numpy y los que va a obtener con tensorflow. \n",
    "\n",
    "**Estructura de la red:** \n",
    "El modelo de red va a ser *LINEAL -> RELU -> LINEAL -> RELU -> LINEAL -> SOFTMAX*. De esta manera, la capa de salida SIGMOIDE es convertida en una SOFTMAX. La capa SOFTMAX generaliza la SIGMOIDE para cuando hay más de dos clases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Crear placeholders\n",
    "\n",
    "Primero debe crear los placeholders para `X` e `Y`. Luego podrá pasar los datos de entrenamiento cuando ejecute la sesión.\n",
    "\n",
    "**Ejercicio:** \n",
    "Implemente la función abajo para crear los placeholders en tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: create_placeholders\n",
    "\n",
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Crea los placeholders para la sesión de tensorflow.\n",
    "    Input:\n",
    "    n_x: tamaño del vector de imagen (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y: número de clases (de 0 a 5, así que C=6)\n",
    "    Output:\n",
    "    X: placeholder para los datos de entrada, de tamaño [n_x, None] y de tipo \"float\"\n",
    "    Y: placeholder para las etiquetas, de tamaño [n_y, None] y tipo \"float\"\n",
    "    Utiliza None porque permite flexibilidad a la hora de especificar el número de ejmplos para los placeholders.\n",
    "    \"\"\"\n",
    "\n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 2 líneas de código)\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=[n_x, None], name=\"X\")\n",
    "    Y = tf.placeholder(dtype=tf.float32, shape=[n_y, None], name=\"Y\")\n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"X_8:0\", shape=(12288, ?), dtype=float32)\n",
      "Y = Tensor(\"Y_2:0\", shape=(6, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_placeholders(12288, 6)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**:\n",
    "\n",
    "<table> \n",
    "    <tr> \n",
    "        <td>\n",
    "            **X**\n",
    "        </td>\n",
    "        <td>\n",
    "        Tensor(\"Placeholder_1:0\", shape=(12288, ?), dtype=float32) (not necessarily Placeholder_1)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr> \n",
    "        <td>\n",
    "            **Y**\n",
    "        </td>\n",
    "        <td>\n",
    "        Tensor(\"Placeholder_2:0\", shape=(6, ?), dtype=float32) (not necessarily Placeholder_2)\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Inicialización de los parámetros\n",
    "\n",
    "La segunda tarea es la de inicializar los parámetros en tensorflow.\n",
    "\n",
    "**Ejercicio:** \n",
    "Implemente la función abajo para inicializar los parámetros en tensorflow. Va a utilizar la inicialización de Xavier para los pesos, y los sesgos se inicializan con ceros. Los tamaños están dados. Por ejemplo, para W1 y b1 puede utilizar: \n",
    "\n",
    "```python\n",
    "W1 = tf.get_variable(\"W1\", [25,12288], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer())\n",
    "```\n",
    "Utilize `seed = 1` para replicar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: initialize_parameters\n",
    "\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Inicializa los parámetros para construir una red neuronal con tensorflow. \n",
    "    Las dimensiones son:\n",
    "                        W1 : [25, 12288]\n",
    "                        b1 : [25, 1]\n",
    "                        W2 : [12, 25]\n",
    "                        b2 : [12, 1]\n",
    "                        W3 : [6, 12]\n",
    "                        b3 : [6, 1]\n",
    "    Output:\n",
    "    parameters: diccionario con tensores conteniendo W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                   # para la replicabilidad\n",
    "        \n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 6 líneas de código)\n",
    "    W1 = tf.get_variable(\"W1\", [25, 12288], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b1 = tf.get_variable(\"b1\", [25, 1], initializer=tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [12, 25], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b2 = tf.get_variable(\"b2\", [12, 1], initializer=tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [6, 12], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b3 = tf.get_variable(\"b3\", [6, 1], initializer=tf.zeros_initializer())\n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = <tf.Variable 'W1:0' shape=(25, 12288) dtype=float32_ref>\n",
      "b1 = <tf.Variable 'b1:0' shape=(25, 1) dtype=float32_ref>\n",
      "W2 = <tf.Variable 'W2:0' shape=(12, 25) dtype=float32_ref>\n",
      "b2 = <tf.Variable 'b2:0' shape=(12, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters()\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**:\n",
    "\n",
    "<table> \n",
    "    <tr> \n",
    "        <td>\n",
    "            **W1**\n",
    "        </td>\n",
    "        <td>\n",
    "         < tf.Variable 'W1:0' shape=(25, 12288) dtype=float32_ref >\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr> \n",
    "        <td>\n",
    "            **b1**\n",
    "        </td>\n",
    "        <td>\n",
    "        < tf.Variable 'b1:0' shape=(25, 1) dtype=float32_ref >\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr> \n",
    "        <td>\n",
    "            **W2**\n",
    "        </td>\n",
    "        <td>\n",
    "        < tf.Variable 'W2:0' shape=(12, 25) dtype=float32_ref >\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr> \n",
    "        <td>\n",
    "            **b2**\n",
    "        </td>\n",
    "        <td>\n",
    "        < tf.Variable 'b2:0' shape=(12, 1) dtype=float32_ref >\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Propagación hacia delante en tensorflow \n",
    "\n",
    "Ahora va a implementar la propagación hacia delante en tensorflow. La función toma de entrada un diccionario de parámetros y completa una iteración hacia delante. Utilice las funciones: \n",
    "\n",
    "- `tf.add(...,...)` para suma\n",
    "- `tf.matmul(...,...)` para multiplicación matricial\n",
    "- `tf.nn.relu(...)` para la activación ReLU\n",
    "\n",
    "**Problema:** \n",
    "Implemente la propagación hacia delante. Puede comparar el código con el equivalente de numpy. Fíjese que la propagación hacia delante en este caso se detiene en `z3`. Esto es porque en tensorflow la capa de salida es dada como input de la función que computa la pérdida. Por lo tanto no se computa `a3`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implementa la propagación hacia delante para el modelo: LINEAL -> RELU -> LINEAL -> RELU -> LINEAL -> SOFTMAX\n",
    "    Input:\n",
    "    X: placeholder para el conjunto de entrada, de tamaño (tamaño de entrada, número de ejemplos)\n",
    "    parameters: diccionario python con los parámetros \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\" con dimensiones dadas en initialize_parameters\n",
    "    Output:\n",
    "    Z3: salida de la última unidad LINEAL\n",
    "    \"\"\"\n",
    "    \n",
    "    # Recupere los parámetros del diccionario \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 5 líneas de código)             # Equivalentes numpy:\n",
    "    Z1 =  tf.add(tf.matmul(W1, X), b1)                                # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                               # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                                # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                               # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                                # Z3 = np.dot(W3,Z2) + b3\n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z3 = Tensor(\"Add_2:0\", shape=(6, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(12288, 6)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    print(\"Z3 = \" + str(Z3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**: \n",
    "\n",
    "<table> \n",
    "    <tr> \n",
    "        <td>\n",
    "            **Z3**\n",
    "        </td>\n",
    "        <td>\n",
    "        Tensor(\"Add_2:0\", shape=(6, ?), dtype=float32)\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Calcule el coste\n",
    "\n",
    "Como ya se ha visto, el coste se compute mediante:\n",
    "```python\n",
    "tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = ..., labels = ...))\n",
    "```\n",
    "**Problema**: \n",
    "Implemente la función de coste. \n",
    "- Fíjese que las entradas de \"`logits`\" y \"`labels`\" para `tf.nn.softmax_cross_entropy_with_logits` deben tener dimensiones (número de ejemplos, número de clases). Por ello se han transpuesto Z3 e Y.\n",
    "- Además, `tf.reduce_mean` hace la suma sobre todos los ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: compute_cost \n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Calcula el coste\n",
    "    Input:\n",
    "    Z3: salida de la propagación hacia delante (salida de la última unidad lineal), de tamaño (6, número de ejemplos)\n",
    "    Y: vector placeholder de etiquetas, mismo tamaño que Z3\n",
    "    Output:\n",
    "    cost: tensor de la función de coste\n",
    "    \"\"\"\n",
    "    \n",
    "    # para ajustarse a los requerimientos de la función tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 1 línea de código)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels= labels))\n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-37-1634eb7e5872>:18: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "coste = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(12288, 6)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    print(\"coste = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**:\n",
    "\n",
    "<table> \n",
    "    <tr> \n",
    "        <td>\n",
    "            **coste**\n",
    "        </td>\n",
    "        <td>\n",
    "        Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 - Retropropagación y actualización de parámetros\n",
    "\n",
    "1Bajo el ambiente de tensorflow, es mucho más sencillo implementar la retro-propagacion, y la actualización de los parámetros se hace en una linea de código. Tras computar la función de coste, debe crear un objeto \"`optimizer`\". Este objeto debe ser llamado junto con el coste cuando se ejecute la tf.session. Cuando se le llame, desempeñará la optimizacion sobre el coste con el método seleccionado y la tasa de aprendizaje.\n",
    "\n",
    "Por ejemplo, para el G.D. el 'optimizer' sería:\n",
    "```python\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "```\n",
    "\n",
    "Para desempeñar la optimización puede hacer:\n",
    "```python\n",
    "_ , c = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "```\n",
    "\n",
    "Esta linea computa la retro-propagación, pasando por el grafo de tensorflow en dirección hacia atrás. \n",
    "\n",
    "Fíjese que al codificar, se hace uso de `_` como una variable temporal/auxiliar para almacenar valores que no se van a utilizar después. De este modo, `_` toma la evaluación de `optimizer`, que no va a ser utilizada luego (y `c` toma el valor de la variable `cost`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 - Construcción del modelo\n",
    "\n",
    "En la siguiente función se juntan las funciones implementadas previamente, en el orden correcto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.002,\n",
    "          num_epochs = 1500, minibatch_size = 24, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implementa una red neuronal de tres capas en tensorflow: LINEAL->RELU->LINEAL->RELU->LINEAL->SOFTMAX.\n",
    "    Input:\n",
    "    X_train: conjunto de entranamiento, de dimensiones (dimensión de los patrones = 12288, número de ejemplos = 1080)\n",
    "    Y_train: etiquetas de entrenamiento, de dimensiones (número de clases = 6, número de conjuntos de entrenamiento = 1080)\n",
    "    X_test: conjunto de prueba, de tamaño (dimensión de los patrones = 12288, número de ejemplos = 120)\n",
    "    Y_test: etiquetas de prueba, de dimensiones (número de clases = 6, número de ejemplos = 120)\n",
    "    learning_rate: tasa de aprendizaje de la optimización\n",
    "    num_epochs: número de épocas para el bucle de optimización\n",
    "    minibatch_size: tamaño de los lotes o mini-batches de datos para optimizar\n",
    "    print_cost: si es True muestra el coste cada 100 épocas\n",
    "    Output:\n",
    "    parameters: parametros del modelo.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # para vovler a ajecutar el modelo sin sobre-escribir las variables tf\n",
    "    tf.set_random_seed(1)                             # para replicabilidad\n",
    "    seed = 3                                          # para replicabilidad\n",
    "    (n_x, m) = X_train.shape                          # (n_x: tamaño del input, m : número de ejemplos de entrenamiento)\n",
    "    n_y = Y_train.shape[0]                            # n_y : tamaño de la salida\n",
    "    costs = []                                        # Hacerle seguimiento al coste\n",
    "    \n",
    "    # Crear los placeholders de dimensiones (n_x, n_y)\n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 1 línea de código)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "\n",
    "    # Initializar los parametros\n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 1 línea de código)\n",
    "    parameters = initialize_parameters()\n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    # Propagación hacia delante: Construye la propagación hacia delante en el grafo de tensorflow\n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 1 línea de código)\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    # Función de coste: Añade la función de coste al grafo de tensorflow\n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 1 línea de código)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    # Retro-propagación: Define el método de optimización (\"optimizer\") de tensorflow optimizer. Usar el método de Adam (\"AdamOptimizer\").\n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 1 línea de código)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    # Inicialización de las variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Empieza la sesión para computar el grafo computacional en tensorflow\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Ejecute la incialización\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Bucle de entrenamiento\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                           # Declara el coste tras cada época\n",
    "            num_minibatches = int(m / minibatch_size) # Número de lotes de datos de tamaño minibatch_size en entrenamiento\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Selecciona una partición de los datos (mini-batch)\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # Ejecuta la sesión para ejecutar el grafo (optimizador + coste), y mediante el feedict se pasan los valores de la partición (X,Y).\n",
    "                ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 1 línea de código)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Muestra el coste cada 100 épocas\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Coste tras la época %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('Coste')\n",
    "        plt.xlabel('Épocas')\n",
    "        plt.title(\"Tasa de aprendizaje =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Se guardan los parámetros en una variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Los parámetros han sido aprendidos\")\n",
    "\n",
    "        # Predicciones corregidas (el máximo se lo lleva todo)\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Precisión en los datos de prueba\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Precisión de entrenamiento:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Precisión de prueba:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ejecute la siguiente celda para entrenar el modelo. Esto puede tomar algunos minutos. Revise que el \"Coste tras la época 100\" sea de 0.906227. Si no lo es, interrumpa el proceso dándole a stop (⬛), e intente corregir el código. Si es el coste correcto, tómese un café y vuelva en 5 minutos.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coste tras la época 0: 1.788405\n",
      "Coste tras la época 100: 0.846758\n",
      "Coste tras la época 200: 0.390060\n",
      "Coste tras la época 300: 0.336921\n",
      "Coste tras la época 400: 0.176128\n",
      "Coste tras la época 500: 0.118099\n",
      "Coste tras la época 600: 0.047386\n",
      "Coste tras la época 700: 0.025934\n",
      "Coste tras la época 800: 0.016343\n",
      "Coste tras la época 900: 0.010477\n",
      "Coste tras la época 1000: 0.008112\n",
      "Coste tras la época 1100: 0.006435\n",
      "Coste tras la época 1200: 0.005122\n",
      "Coste tras la época 1300: 0.004259\n",
      "Coste tras la época 1400: 0.003684\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEYCAYAAABPzsEfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcXHWZ7/HPU129d6c7ne4sZCMkAQxLAsaACgguGFQG\ndXAMLjMuDDIjjnodZ0C9uMzMxauOOy6RQdDrgDqyqeyKIotC2EICCQkhIVsnna2XpPd67h/nVHV1\np6q70unqqpN83y/qVafOVs/pIvXUbz3m7oiIiIwkVugAREQkGpQwREQkJ0oYIiKSEyUMERHJiRKG\niIjkRAlDRERyooQhkWBmFWbmZjaj0LGMpaHXZWY3mNm/HOY5v2hm3x2bCEUGKGHIQcysI+2RMLPO\ntNfvLXR8RzJ3/4C7f+Uwz/F5d79irGLKxMyazOzXZrbfzF4ys4tH2P9KM9thZq1m9kMzK83lXGZ2\ntpn93sz2mFmLmd1kZpPzeW2SnRKGHMTda5IP4GXgwrR1Pyt0fIVkZvFCx1AklgN7gcnAh4HrzWx+\nph3N7CLgn4BzgOOAU4DP5niueuC7wGzgWCAR7i+F4O566JH1AWwE3jhk3WuBvwD7gG3AN4B4uK0E\nuBZoAVqBZ4ATwm3vCF+3ESSiz4zw3p8FdgBbgEsBB2aE2yqBbwKbgWbgO0B5lvOcCPwB2BPGdSNQ\nm7a9GfgXYE24z/LkuYClwHrgf4ex/CjtWlaGf4M/AQuGnO+TwKrwb/AzoCzH67oZ+Fy4fC/QkfZI\nAMvCbd8Pj28DHgPOTDv/l4Hr0l6fnfZ5PQm89jD/n5gI9AGz09b9AvhClv1vAa5Oe/0WYOMoz/Ua\noKXQ/y6O1odKGDIavcAVwCSCL6MLCb74AN4GnA7MJfgyeA/Br0cIvtzeQ/Cr8e3AP5vZ0kxvYGZv\nB/4ReB3BF/4FQ3b5OjCD4NfqCcDxwJXDxPwlYGra/p8dsv0S4PXhttOAT6dtOxYoBWYC/2RmZwLf\nAz4Y/g1+Ctw2pPRxMfAGYB5wRnjduVxXiruf7wMlvfcRJOc/hpsfDa9lEnA78Mv0ap4kMzsWuC28\n3gbgc2GsEzO9p5ndZ2b7sjz+J9ztRKDd3TelHfoMcFKWSzkp3J6+72wzqxnFuc4BVmfZJnmmhCGH\nzN0fc/fH3b3f3V8EriP4AoQgmUwg+CLA3Ve7+85w+Xfh64S7P0nwS/J1Gd4C4G8Ifs2vcfcO4IvJ\nDeEX84eBj7v7PndvJfhVvSxLvGvc/ffu3uPuzQQlk6Hv+y133+buLcA1BAkkqRv4t/D4TuAjwHfd\n/Ynwb7AcKAdemXbMN9x9R3i+O4FFI11XNmZ2EvAj4J3uvj28pp+4+1537wX+D0HiOC7D4X8H3OLu\n94d/9zuB54Dzs/yt3uTu9VkeybaFGoKSU7o2oDbLJQzdvy1tfc7nMrNXAv8aPqQAlDDkkJnZAjO7\nK2zEbAOuBhrDzXcB/wX8EGg2s++FvyQxs9ea2R/DxstW4ANpxw11DEF1U9KmIdtKgdXJX78Ev6Iz\nNoaa2TFm9ksz2xrGe12G9x36XsekvW4Ov5iTZgOfSf/1DTQB09OPSVs+QPDFONJ1ZYq9gaAE8Sl3\nfyxt/VVmtjb8O+4FKjJcUzLW9w2JdfGQ6ztUHQQ/CtLVAe057l+Xtj6nc5nZK4DfAB9x97+MImYZ\nA0oYMho/IqgLn+vuEwiqewzAA19399OAU4GFwMfD434B/ByY6e51wA3J4zLYTlAFlDRryLa+8P2T\nv37r3H1SlnN9FdgPnBzGe2mG9x36XtvSXg+d0nkzQZ18+q/vKne/Jcv753pdg5hZCcHf7A53/0na\n+jcBHyNoR6knqGrqzHBNyVivGxJrtbt/I8t7/n5IL7n0x63hbmuACWaWHvtCslcVrQ63p++7KSxh\njXguM5tL0J7zGXf/RZb3kHGghCGjUQu0untHWF3y98kNZnammS0Oq432Az1AwsyM4Ff2bnfvMrPX\nAO8a5j1+AVxqZseHJZSrkxvCX/vXA98ys0YLzAy/SLPF2wG0hV9M/yvDPv9kZtPMrJGgLeTnw8S2\nHPhYeJ1mZjVm9ldmVjXMMSNeVwZfI2jo/vSQ9bUEVX8tQBlBwq7Ico4bgXeZ2RvMrMTMKsPlqZl2\ndvfXe1ovuSGPd4T77CX4tf8lM6sys/OANxM07mfyE+Aj4TVPImhPuSGXc5nZbOD3wFfc/cfD/K1k\nHChhyGh8kuBLr4OgR1T6l2s9wZfBPmADQZXLt9zdgcuBr5lZO0GvpF9mewN3v5Xgi/lPBL9C7xmy\nyycISgErCOrA7yZoYM7kauCscL9bgV9l2Odm4AFgHfAskHUshLs/TNBN9Ifhdb5A0Kg94s1lcriu\ndJcQdCpoTfuV/9fAr4EHgRcJ/sa7CJJHpvfbAPw1QVvJLoLP4+Mc/r/9vyeoAtsF/Bj4sLuvAwgT\nQ0dyvIS730bQNfahMN5VwH/kci6C/2dmAdek/Q12HWbsMkoW/DsWOXqZWTNwsbs/VOhYxoKZfQWo\ncfd/LHQscmRRCUPkCBJW/S0AXip0LHLkUcIQObKsZqBaUGRMqUpKRERyohKGiIjk5IiaSK2xsdGP\nPfbYQochIhIZTzzxxC53b8pl3yMqYRx77LGsWLGi0GGIiESGmQ0720A6VUmJiEhOlDBERCQnShgi\nIpITJQwREcmJEoaIiORECUNERHKihCEiIjk56hNGb3+Cax9Yz4MvZJwdWkREQkd9wojHjB/9aQN3\nrWoeeWcRkaNY3kZ6m9n1wNuAne5+cobtnwbemxbHK4Amd99jZhsJ7unbD/S5++I8xskJU2pZ29w2\n8s4iIkexfJYwbgCWZtvo7l9190Xuvgi4Cviju+9J2+W8cHvekkXSCVNreWFHB5q5V0Qku7wlDHd/\nENgz4o6BS4Cb8hXLSE6YWktHdx9b93UWKgQRkaJX8DYMM6siKImk32fZgfvN7Akzu2yE4y8zsxVm\ntqKlZXQN1ydOrQVgbXP7qI4XETkaFDxhABcCDw+pjjorrKq6APiomZ2T7WB3X+7ui919cVNTTjP0\nHmT+lCBhrFHCEBHJqhgSxjKGVEe5+9bweSdwK7AknwFMqChlZkMlq7e15vNtREQiraAJw8zqgNcB\nt6etqzaz2uQycD6wKt+xLJxRzzOblTBERLLJZ7fam4BzgUYz2wJ8HigFcPcfhLu9A7jX3fenHToF\nuNXMkvH9t7vfna84kxbNrOc3K7fT0t5NU215vt9ORCRy8pYw3P2SHPa5gaD7bfq6DcDC/ESV3cKZ\n9QCs3LKPN7xiyni/vYhI0SuGNoyicNIxE4gZPLN5X6FDEREpSkoYoaqyODMmVrFx94FChyIiUpSU\nMNJMq6tge6sG74mIZKKEkeaY+kq27esqdBgiIkVJCSPN1LoKdrR1kUhoTikRkaGUMNIcU1dBX8LZ\n1dFd6FBERIqOEkaaaXWVAGxrVbWUiMhQShhpptVXALBds9aKiBxECSNNsoSxXSUMEZGDKGGkmVhV\nSnk8pq61IiIZKGGkMTNmNWjwnohIJkoYQ8ybXMP6nR2FDkNEpOgoYQwxf3INm3bvp7uvv9ChiIgU\nFSWMIeZOriHhsHGXqqVERNIpYQwxb3INgKqlRESGUMIYYm5TDWawbqfu7y0ikk4JY4iK0hLmNdXw\n8PpdhQ5FRKSoKGFkcPErZ/D4xr2sbVYpQ0QkSQkjg3ctnklZPMYvVmwudCgiIkUjbwnDzK43s51m\ntirL9nPNrNXMng4fV6dtW2pma81svZldma8Ys2moLmNuUw0bd+0f77cWESla+Sxh3AAsHWGfP7n7\novDxJQAzKwGuBS4AFgCXmNmCPMaZUWNNmaY5FxFJk7eE4e4PAntGcegSYL27b3D3HuBm4KIxDS4H\nTTXl7OroGe+3FREpWoVuw3iNma00s7vM7KRw3XQgvfFgS7guIzO7zMxWmNmKlpaWMQussbaclo5u\n3HX3PRERKGzCeBKY5e6nAt8BbhvNSdx9ubsvdvfFTU1NYxZcY00ZPX0J2rv7xuycIiJRVrCE4e5t\n7t4RLt8JlJpZI7AVmJm264xw3bhqrCkHYLeqpUREgAImDDObamYWLi8JY9kNPA7MN7M5ZlYGLAPu\nGO/4kglDDd8iIoF4vk5sZjcB5wKNZrYF+DxQCuDuPwAuBv7BzPqATmCZBw0GfWZ2BXAPUAJc7+6r\n8xVnNqmE0a6EISICeUwY7n7JCNu/C3w3y7Y7gTvzEVeuGmvLAJUwRESSCt1Lqmg1VJVhBi1qwxAR\nAZQwsoqXxGio0uA9EZEkJYxhTJlQwbZ9nYUOQ0SkKChhDGNOU7XmkxIRCSlhDGPOpGo27+2ktz9R\n6FBERApOCWMYcxqr6U84m/fo/t4iIkoYwzi2sRqAl1QtJSKihDGc45QwRERSlDCGMbG6jLrKUjYo\nYYiIKGGMZGZDpbrWioighDGi4EZKGrwnIqKEMYLGmnJaNAGhiIgSxkiaasvZ3dFDIqE774nI0U0J\nYwSNNeX0JZzWzt5ChyIiUlBKGCNoqg3ui9GidgwROcopYYxAN1LKj97+BL9+ZhvBPbNEJAqUMEbQ\nFN5ISSWMsfXQul187KanWLujvdChiEiOlDBG0FRTAaCeUmOsuy+Y0LGnTxM7ikSFEsYIJlTGKSuJ\nsUt33htTyaoodT4TiY68JQwzu97MdprZqizb32tmK83sWTN7xMwWpm3bGK5/2sxW5CvGXJgZjTVl\nKmGMsWSiSKgNQyQy8lnCuAFYOsz2l4DXufspwL8By4dsP8/dF7n74jzFl7Nj6ivZtFvzSY2lZKJQ\no7dIdOQtYbj7g8CeYbY/4u57w5d/BmbkK5bDdcqMOlZta6VPN1IaMwlVSYlETrG0YXwYuCvttQP3\nm9kTZnbZcAea2WVmtsLMVrS0tOQluEUz6+nqTahHzxhKFiw0gl4kOgqeMMzsPIKE8a9pq89y90XA\nBcBHzeycbMe7+3J3X+zui5uamvIS46KZ9QA8s7k1L+c/GqmEIRI9BU0YZnYqcB1wkbvvTq53963h\n807gVmBJYSIMzGqoYmJVKU+9vHfknSUnyUShNgyR6ChYwjCzWcAtwPvd/YW09dVmVptcBs4HMva0\nGi9mxqvnTuKBtTvVjjFGVMIQiZ58dqu9CXgUOMHMtpjZh83scjO7PNzlamAS8L0h3WenAA+Z2TPA\nY8Bv3f3ufMWZq4sWTWdXRw8/X7FZXWzHwMA4DGUMkaiI5+vE7n7JCNsvBS7NsH4DsPDgIwrr3BOa\nmFAR57O3ruKuZ5v5f5eeUeiQIk3jMESip+CN3lFRHi/hKxcHeWzFpj2qez9MA+MwChyIiORMCeMQ\nLD15Kle/bQFdvQlNRniYVMIQiR4ljEN0/JRaANbt6ChwJNGmuaREokcJ4xAdP6UGgHUaxHdYkgP2\nVMIQiQ4ljEPUVFtOXWUpL+xUCeNwaByGSPQoYRwiM2P+5BrWq0rqsGgchkj0KGGMwqxJVby850Ch\nw4i0hMZhiESOEsYozGqoYkd7F919/YUOJbIGekkVNg4RyZ0SxijMnFiFO2zd21noUCJL98MQiR4l\njFGY2VAFwGYljFFzH/wsIsVPCWMUZjZUArBZ7Rijpm61ItGjhDEKU2orKCuJsXmvEsZoqQ1DJHqU\nMEYhFjOmT6xkyx5VSY2WekmJRI8SxijNnlTFiy0aizFarkZvkchRwhilhTPqeWFHO+1dvYUOJZJU\nJSUSPUoYo3T67IkkXPf5Hi1VSYlEjxLGKC2aWY8ZPKn7fI+KShgi0aOEMUp1laXMn1zDE5uUMEZD\nbRgi0ZPPe3pfb2Y7zWxVlu1mZt82s/VmttLMTk/bttTM1obbrsxXjIfr1Bn1rN6mKqnRSFVJqYgh\nEhn5LGHcACwdZvsFwPzwcRnwfQAzKwGuDbcvAC4xswV5jHPUXjFtArs6etjZ3lXoUCJHVVIi0ZO3\nhOHuDwJ7htnlIuAnHvgzUG9m04AlwHp33+DuPcDN4b5F5xXTgrvvPb9dN1M6VGr0FomeQrZhTAc2\np73eEq7Ltr7oLJg2AYDnt7cVOJLo0VxSItGTU8II2xveZ2ZXh69nmdmS/IaWGzO7zMxWmNmKlpaW\ncX3v+qoyqstK+PJda7j69oxNNZKFShgi0ZNrCeN7wKuBS8LX7QTtDIdjKzAz7fWMcF229Rm5+3J3\nX+zui5uamg4zpEN37omTAfjJo5vUgHsIdMc9kejJNWGc4e4fBboA3H0vUHaY730H8Ldh6eVMoNXd\ntwOPA/PNbI6ZlQHLwn2L0pffeQqffvMJAGzdp7mlcjXQ6K2MIRIV8Rz36w17LzmAmTUBieEOMLOb\ngHOBRjPbAnweKAVw9x8AdwJvAdYDB4APhtv6zOwK4B6gBLje3Vcf2mWNn9qKUs48bhIAa5vbU/fK\nkOFpHIZI9OSaML4N3ApMNrP/AC4G/vdwB7j7JSNsd+CjWbbdSZBQIuH4KTUArN3RzhsXTClwNNGQ\nCH9uqEpKJDpyShju/jMzewJ4A2DA2939+bxGFiG1FaVMr69kbbO61+ZKjd4i0ZNTwjCzn7r7+4E1\nGdYJcMLUWtY0q3ttrjRwTyR6cm30Pin9Rdie8cqxDye6Tp5ex/qdHezv7it0KJGgNgyR6Bk2YZjZ\nVWbWDpxqZm3hox3YCdw+LhFGxGkz60k4PLtVc0vlQlVSItEzbMJw92vcvRb4qrtPCB+17j7J3a8a\npxgjYeHMegDuenY7z2zeV+Boip+qpESiJ9cqqd+YWTVAOOL762Y2O49xRU5DdRnxmHHjo5u46NqH\nCx1O0VMJQyR6ck0Y3wcOmNlC4FPAi8BP8hZVRF20aGDKq90d3QWMpPhpLimR6Mk1YfSF4yYuAr7r\n7tcCtfkLK5r+/e0n861liwBYt7OjwNEUN90PQyR6ck0Y7WZ2FfB+4LdmFiMctS0DKstKWDKnAYB1\nOzQmYziaS0okenJNGO8GuoEPuXszwYSAX81bVBE2dUIFNeVxlTBGoLmkRKInp4QRJomfAXVm9jag\ny93VhpGBmTFvcg3rdihhDEfjMESiJ9f7YfwN8BjwLuBvgL+Y2cX5DCzKTp4+gRWb9vDLFZt5add+\nfrtye6FDKjr9CVVJiURNrpMPfhZ4lbvvhNRstfcD/5OvwKLsU286gRd37ueqW56lL/xGfNOCCyiL\nF/IGh8VFVVIi0ZPrN1gsmSxCuw/h2KPOxOoyvnLxqYO+DF/es7+AERUfNXqLRE+uX/p3m9k9ZvYB\nM/sA8FsiNP14IcxsqOJtpx6Ter2hRQkj3cA4DGUMkagYaS6peWb2Wnf/NPBD4NTw8SiwfBzii7T/\n885T+PUVZwGwYZcSRjqN9BaJnpHaML4JXAXg7rcAtwCY2SnhtgvzGl3E1ZTHOWVGHY01ZbykEsYg\nqpISiZ6RqqSmuPuzQ1eG647NS0RHoOMaa9iwS91s06nRWyR6RkoY9cNsqxzLQI5kcxqrebFlv+rr\n0wyMwyhwICKSs5ESxgoz+/uhK83sUuCJkU5uZkvNbK2ZrTezKzNs/7SZPR0+VplZv5k1hNs2mtmz\n4bYVuV5QMTpp+gT27O/h5T0HCh1K0VAJQyR6RmrD+ARwq5m9l4EEsRgoA94x3IHhXfmuBd4EbAEe\nN7M73P255D7u/lXCKUbM7ELgk+6+J+0057n7rkO4nqL0mrmTAHj0xd3MnlRd4GiKg9owRKJnpBso\n7XD31wBfBDaGjy+6+6vD6UKGswRY7+4b3L0HuJlgtttsLgFuyjXwKJnbVENTbTmPbthd6FCKhkoY\nItGT00hvd38AeOAQzz0d2Jz2egtwRqYdzawKWApckf62wP1m1g/80N0zduM1s8uAywBmzZp1iCGO\nDzPjzOMm8eiLu3F3zKzQIRWc5pISiZ5iGa19IfDwkOqos9x9EXAB8FEzOyfTge6+3N0Xu/vipqam\n8Yh1VBbOqGNnezf7DvQWOpSiMHA/jAIHIiI5y2fC2ArMTHs9I1yXyTKGVEe5+9bweSdwK0EVV2Ql\n2y42qeEbGEgUqpISiY58JozHgflmNsfMygiSwh1DdzKzOuB1wO1p66rNrDa5DJwPrMpjrHk3e1IV\nAJt2awAfDCQKpQuR6Mh1ttpD5u59ZnYFcA9QAlzv7qvN7PJw+w/CXd8B3Ovu6d+kUwh6ZyVj/G93\nvztfsY6HWQ3JhKESBmguKZEoylvCAHD3OxkySWFaoki+vgG4Yci6DcDCfMY23ipKS5gyoVwJI6Ru\ntSLRUyyN3keF2ZOqNc15SJMPikSPEsY4mt1QxabdB9i0ez/X/WnDUV0d46lxGIWNQ0Ryp4Qxjk6c\nNoGd7d185KdP8O+/fZ61O9oLHVLBJDQOQyRylDDG0bsWz6CuspQ1zUGi+P2anSMcceTSSG+R6FHC\nGEcTKkr5+Bvm01hTxnFN1TxwVCcMDdwTiRoljHH2obPm8Nhn3shbT5nGE5v20tp5dI78dpUwRCJH\nCaMAYjHj1XMnkXB4ctPeQodTEAndD0MkcpQwCuS0mRMpLTH+8tKekXc+AqlbrUj0KGEUSGVZCSdP\nr+PxjUdrwkg+K2GIRIUSRgEtmdPAyi376Ozpp7m1q9DhjCvXSG+RyFHCKKCz5jXS2+/89fcf4cxr\nfseOtqMnaSQ0l5RI5ChhFNCSOQ1Ul5Xw3PY2AF7c2VHgiAJfu2ct/3nv2ry+h+aSEokeJYwCKo+X\ncPb8gZs+Fcu9Mh55cRcPr8/vrdQTCTV6i0SNEkaBvfP06UysKgWKZ+rz3n6nsze/I+o0l5RI9Chh\nFNj5J03lqavP57jG6qK5uVJvf4Ku3v68vofmkhKJHiWMIjFrUjCTbTF8gfb2J+jsyW/C6Nc4DJHI\nUcIoErMbqnhuexuv+o/72dXRXdBYgiqpfJcwBj+LSPFTwigS0+orAdjV0cPqbW0FjaW3P5H3hOEq\nYYhEjhJGkbhw4TFcuPAYoPDda3v7E/T0JejP48//gXEYeXsLERljeU0YZrbUzNaa2XozuzLD9nPN\nrNXMng4fV+d67JFmen0l3162iNqKOBt2dbDvQA/X3Pl83tsSMunpC3pI5bPhO9tcUgd6+vjEzU/R\n0l7YajkROVjeEoaZlQDXAhcAC4BLzGxBhl3/5O6LwseXDvHYI4qZMbephg0t+/n1yu388MEN/G7N\njnGPoy/8+Z+vail3zzq9+Zrmdm57ehtPvnx0zuIrUszyWcJYAqx39w3u3gPcDFw0DsdG2nFN1Wxo\n2c8T4aSED6/fPe4x9PYHJYx8lW7Sc8TQGyj1hqWbvn7VVYkUm3wmjOnA5rTXW8J1Q73GzFaa2V1m\ndtIhHouZXWZmK8xsRUtLy1jEXVBzm2pobuviwXXBSOtHXszviOuh3J3e8Ms6X1VS6aWKod2Ie8Jk\nlUxaIlI8Ct3o/SQwy91PBb4D3HaoJ3D35e6+2N0XNzU1jXxAkTtleh0Ae/b3MKshGJvx8jiOAO9N\n+2Wfryqp9Lb0oe3qyfYTJQyR4pPPhLEVmJn2eka4LsXd29y9I1y+Eyg1s8Zcjj1SnT2/kbeeOg2A\nz7zlFcRjxg8ffDHjvr39CT5/+yq27escs/dP/6LOV5VUegljaBvGQMJQlZRIsclnwngcmG9mc8ys\nDFgG3JG+g5lNNTMLl5eE8ezO5dgjlZnxnWWncc8nzmHpyVO5ZMksbn58M1v2HlzKWNvczo2PbuKB\ntTvH7P0HJYy8NXoPLB9Uwgjfv29o44aIFFzeEoa79wFXAPcAzwO/cPfVZna5mV0e7nYxsMrMngG+\nDSzzQMZj8xVrsYnFjBOm1gLw7lfNpD/hrNraetB+yZsu7TvQO2bvnf7LviBtGGEJI/ksIsUjns+T\nh9VMdw5Z94O05e8C38312KPRzIlVAGzZe3C1U3NbMmH0jNn7jUcJY9gqqVQJQ1VSIsWm0I3eMoIJ\nlXFqy+OZE0ZeShjpbRj5+ZWfU6O3ShgiRUcJo8iZGdMnVrJl7wG6+/r577+8nKoq2p5MGJ15Shh5\nHLiXlLXRWyUMkaKT1yopGRszJlayZW8nV9+2mp+v2ExpifGuxTNpbgtKHWNZJdXTl9attqdvzM6b\nLpkL4jE7aC6pXo3DEClaShgRMGNiFfc/v5M1ze0AbNgV3Ghpe76rpPLchlESs6wljD4lDJGioyqp\nCJgxsTK1PGVCOS80t7O9tZPt+/JcJZW3NowgScQzJIzufo3DEClWKmFEwKSaMgAWz57ItPpK7n9u\nB6++5vcAlJXE2HegB3cnHNJyWMZjpHcyR5TEjN6+bAP3VMIQKTYqYUTA2fObOOf4Jr7x7kWcOLV2\n0Bf5a+dNorffOTBGo7LTv6jzPQ4jXhLLOg5DCUOk+ChhREBjTTk/+dASZjZUcfyUYEDfslfN5IV/\nv4ClJ08FDq6WGu3Nj8ZnapDgOWjDyPz+mq1WpPgoYUTMkmMbeO28SVx69hzK4jHqq4Lqqr37e2hu\n7aI/4Wzec4C5n7mTW57ccsjnT35hl8Vjg0oyP/3zJq658/kxuYZEInsbRmqkt0oYIkVHCSNi6qpK\n+dmlZzJvclDSqK8sBeCPL7Rw5jW/48ZHNvIv/7MSgD+sPfTp3nvCX/YTKuIcSOtWe+/qZn79zLbD\nDR8Y3IbhPnhcRk8OJYzm1i71ohIpACWMiEuWML56z1oArn/4JR7dENx0KV5yaI3grZ29qTEdMyZW\npbrtAuzq6Bmz3ljpvaRg8GSEqW61WSYf7Ozp57yv/YFbnjoqJi8WKSpKGBE3fWIl0+srqasspaqs\nJDWFyMSqUvbszz6g7xv3vcDdq5oHrfvoz57k6tuDOR7nTa5h277O1Bf47o5uDvT00913+O0a6eMw\n0l/DQAmnJ0sJo727l87eft3zW6QAlDAirqY8zsNXvp5nPn8+n37zCQDMbKhk4cx6dndkTxg3Prrx\noCqmzWlTqM9tqiHhsG1fJ4mEp5LPs1taD/t+2wMjvWODXgP0hAkpW5VTd2+wPl89uEQkOyWMI8gr\nZ08E4LVzG2moLmN3RzcXf/8Rbn86qL757u/X8ZcNu+lPOK2dvQeVQFrTqpzmTa4BYNOeA7R19aZm\nj/3cbas8VlT3AAAUfklEQVT4p5ueOqw4fUgJw0krYYzQrTaZKLo1OaHIuFPCOIIsmDaBd542nfec\nMYtJ1WVsa+1ixaa9/O75nfT2J/j6fS/wyye20NbZizuDEkYi4bSlJYy5TdUAvLznALvSSirrdnYM\nW9WVye6Obq5/6KVUokiVMEoytGGMMNK7KyxhdKuEITLulDCOIPGSGF9/9yJOnVHPpJry1Po1zW1B\n1ZLDjrYu9oQN23vSJi3s6OkbVDV0TH0l5fEYL+/ePyhB9Cf8kNsy7nx2O1/6zXNsDW8lO2wbxggl\njOT7JhOHiIwfJYwjVEN1WWp5Q8t+1u/sAIKEkewJtXd/T+pXf+uQCQzL4zFmNVSxcfcBdncc3MD8\n6Iu7uSPHbrZtXUH33LbO4HloL6n0RJUsWWTrVpsqYYxB47uIHBrNJXWEmpSWMPoSnhqT0dzaxd79\nvan1bV191FWWDmq/gOA+HItm1vOrJ7dkTBj/ee8LvLRrP3+18JgRY2kPE0Z7V/Ae6eMw4NBKGMk2\nDJUwRMZfXksYZrbUzNaa2XozuzLD9vea2Uoze9bMHjGzhWnbNobrnzazFfmM80iUrJIqjwcf8X3P\n7QCCX/vb2wbGVySrm9oyjLH44kUnsXh2A0++vA8IJjpMWreznY7uvlQSGE5Hd7BPMnEkE0RpeD5P\n++7vTt1AKUvC6Es2equEITLe8pYwzKwEuBa4AFgAXGJmC4bs9hLwOnc/Bfg3YPmQ7ee5+yJ3X5yv\nOI9UyRLGGcdNorK0JHX/b4C1zW2p5WTCGFrCAKgqi/Op849PvZ5YXZpaTv7C35F23mw6kiWMMHEk\n57nKXMIIEsHQWWyHvq9KGCLjL58ljCXAenff4O49wM3ARek7uPsj7p7s1P9nYEYe4zmqJNsw5jXV\n8PbTpg/atmZ7e2p5uIQBsGROQ2p5YlXZQdubW0ceQDdQJZUsYQTr4xkH7g0/0nugW61KGCLjLZ8J\nYzqwOe31lnBdNh8G7kp77cD9ZvaEmV2Wh/iOaNXlca664ESWLZnJh8+aAwTzQwGpO/dB0PAN0Jal\nasnMuPeT53DrP76G+qrSg7Y351DCaO9ONnon2zCGljAG9k02evdkGWehcRgihVMUjd5mdh5Bwjgr\nbfVZ7r7VzCYD95nZGnd/MMOxlwGXAcyaNWtc4o2Kj7xubmr5++89nZkNVbztOw/R0d3H9PpKtu7r\nTHWtzVbCAFJTqjdUlzF1QgUtHd2paqVMVVLtXb3s7+5nal0FkFYldVAJI2zDCBNIf8JT5+3LMj17\nMlFopLfI+MtnCWMrMDPt9Yxw3SBmdipwHXCRu+9Ornf3reHzTuBWgiqug7j7cndf7O6Lm5qaxjD8\nI8sFp0zjpGMmUF1WAsAx9RWUx2ODqqSSv/iz+cdz53HNX59CXeVASaO5dXDCuP+5HZzyhXs572t/\nSH2pdyRLGEMavYeWMJKlCrNhxmGohCFSMPlMGI8D881sjpmVAcuAO9J3MLNZwC3A+939hbT11WZW\nm1wGzgdW5THWo4KZ8dZTpwHQ0d3PpOqy1Bd+a2cf08ISQTYnT6/jvBMmp6qmYgZPvryXP60bmEb9\nf54I7sHR2dufOneyJ1Xy+eBxGIOroarL4vT2+0F34wPo6lOjt0ih5C1huHsfcAVwD/A88At3X21m\nl5vZ5eFuVwOTgO8N6T47BXjIzJ4BHgN+6+535yvWo8mnzg8mKJwyoZwlcxp4cF0LPX0JWjt7B43d\nGE7yHhyzGqpYva2ND/74cVrau3F3Htu4J5V4trd24e6pEkaySirbOIxkg3d1eVAKylQtpUZvkcLJ\naxuGu98J3Dlk3Q/Sli8FLs1w3AZg4dD1cvimTKjgvk+ew6Sacp56eS+3Pb2N0//tPjq6+zh7fmNO\n50jeg2NSTTkbdx+gL+Hc+tQWzjthMnv29/CR1x3HD/+4gR1tXXT3JVIN2QeVMMK5pNZsb2fGxKqB\nhFEWB7rp63dKSwa/txq9RQpHU4McheZPqaWhuoyz5wdtPh3dfbzhxMkse1VunQYmVpXRWFPGl995\nCt9atojTZ9Vz8+ObeWj9LoDU6O/trV2pUgUc3OidLGFc+pMVrNraOlAlVR78jsl0m9ZkVVRPXyJ1\nq1cRGR9F0UtKCqMsHuOOK15LRWlJqifUR/87WD+cfzh3Lm8/7RjmT6ll/pRaYmZ87Kan+PJda1gw\nbQILpk2gtiJOc2tnqjqqLB5Ldd0daMMYeJ9Nuw+kplSvChvmM90TI713VE9/gopYyUH7iEh+KGEc\n5U6dUT/o9covnM9IN3adN7km9eUO8LZTp/FfD73E05v3cfWFCzAzptVVsL21K9WldlpdReoueUPH\nYQDsbO9iVkMVENwUCjJPcZ5eFdXV20/F0DorEckbJQwZZELFwYPzRmJmXPve01m5eR9nHjcJCNpK\ndrR1paYDOaaukk27D/DFX6/mjHD0eHxQwuhOtXEku+1m6lqbXsJQO4bI+FLCkDExvT64t3jStLoK\n1ja3p9otklOV/PjhjalSwaASRls361uCKdhPmBpUj2VMGGlJoltda0XGlRq9JS+m1lXS0tHN89uD\niQ5PmzVQ9bU2nJokvYTR0tHN+p0d1FbEmT4xSDyZutWm32mvS11rRcaVEobkxdKTplJTFueb96+j\nrCTGu181k5VfOJ+K0lgqicQGlTC6WLejg/mTa1LTnmeaT6qrtz81Wl0lDJHxpSopyYsFx0zg1o++\nht+ubObChdOoDdtG5k+u5dmtrZSVxGhMu41sS3s3uzp6eMOJk1P33cg8cC9BXWUp+3v6VcIQGWcq\nYUjezJtcy8ffOJ/jmgZ6VCW77549v5H93QNjNHbv72FXRzfzJtekBvR974H1qdl0k7r6+pkQNoqr\nhCEyvpQwZFwdPyVIHm8+aWpq3UnHTEgtnzC1NlUlde9zO/jqvWsHHd/dm0jNZaXpQUTGl6qkZFy9\n4RVTeGj9Lt580lQqymJUl8eZVF3GP/zsSeqrSnntvEae3rw3tf8vHt/MR845jtmTqnF3uvr6U91u\nNQGhyPhSCUPG1bzJNfz0w2dQV1VKebyE9505m1fPncS7XjmDuz5+NiUxoyRtBHi8xPjm/euAYGS3\nO9RXBl10VcIQGV8qYUjB1VeV8dV3Dcw1mZwa5BNvnE9nbz/LH9zAeSdOTm2vq1IJQ6QQLNM9B6Jq\n8eLFvmLFipF3lKL3wo525k+uYd+BXi7+wSO82LIfgBkTK7n2Padz0bUPA8H4jn9demJqhHkmz25p\nZUJlnNmTqjNu//4fXmTP/m4++9YFY38hIkXOzJ5w98W57KsShhSlZG+qidVl3P2Jc3ho3S7KS2Ms\nnh1MK1JRGqM8XsLOtm6WLf8z/+tNx/Ox18/DbPBMWB3dfbznuj8zp7GaO64I7gDs7rgH40DcnR8/\n/BJtXb3885tPoDyuualEslHCkKJXWhIbVCUF8Phn30hVWZzuvn4+d+sqvn7fC9z82MucMLWWxcc2\n0N2XYHZDFZv3HqC9q4+VW1p5evM+FkybwPv+6y/UV5byw/e/kjXN7ewMJ0VcuaWVVx3bUIhLFIkE\nJQyJpORAwKqyOF9710JOmVHHyi2tPLu1lQfWDu6Ke+qMOja07OcjP13B1AkVPLOlFYDP3baK25/e\nltrvzy/uHpQwWg/0smt/N3PTxpGIHM3UhiFHnNYDvZTFY6za1sq2fZ0smdPAuh0d/Owvm9i0+wDn\nL5jCrU9vZfOeTgAWTJuAAzvaunjd8U2ceVwD7vD9P75Ic2sXv/nYWfS7s7a5nb9aeMxB1V4iUXYo\nbRhKGHJU2ravk87efspKYpTFYzy5aS83P76ZJ1/em5pht7Y8Tmk8lroveW+/c/L0CbiTKomcPL2O\nuspSKktLiJcYNeXxQYMPRYpd0SQMM1sKfAsoAa5z9y8P2W7h9rcAB4APuPuTuRybiRKGHK7Onv7U\njZ4mVMbZsGs/1z/0EnWVpdRXlXL/czupKi/h+e1tGEZn78FjQeIxo76qlAkVpVSWldDbn2BSdTlT\n6ypoqi2nPB6jJGbEY0ZFaQnV5XGqykqoDJcry0qoKiuhqjROeWmM0pIYpSVGaUmMspLYoEkbRQ5X\nUSQMMysBXgDeBGwBHgcucffn0vZ5C/AxgoRxBvAtdz8jl2MzUcKQ8dTbn+DlPQc40N3PgZ4++t3Z\nu7+X1dta2dfZS2tnL109/ZTEjN37e2hu7aKlo5u+/gSHczvyeMxSSaQsnkwoaUklHkvbXkJZiaX2\niZcYpbEYpXEjHgv2iZfEKI0FzyUxI2ZGzEgtl8SMWMwoCdebBTfNSu4XM0tbR2p9+j5ZjyF8Hctw\nDME+MTNisYHzQvr7hPvEBo6JHRSLgXHwMTZ436O1qrFYutUuAda7+4YwqJuBi4D0L/2LgJ94kLX+\nbGb1ZjYNODaHY0UKqrQklrFB/K2nThvx2ETC6U0k6OpJcKC3jwM9/XT29HOgJ0g+B8Llnr4Evf3B\no6c/QW+fD3o9sN3D7Wmv+xK0dfam9k+u60sEy739Cfr6PfVaOCiZhf+lXoe5BwgSTJi/wn0Gtqe2\nhcdC+rbw3KnlgWRlltz/4H0Ycl7S1k+qLucXl7967P8gQ+QzYUwHNqe93kJQihhpn+k5HguAmV0G\nXAYwa9asw4tYZJzEYkZ5rITyeAl1HPptcceau9OfcPrDMSrJ5UTC05bBcRI+MJYl4cHrhHvauuT6\nwfv4kOfkPozmGMLlBAcfkxZjIjFwXOoYTzsmkeGY1HsG68P/UtcHydfB9tQ690HrSS0T7hPsO3AO\nH7Q9+V7J86efM/1cQ9fjUFsxPh1eI9+t1t2XA8shqJIqcDgikWRmxEss+l8Iklf5/P9jKzAz7fWM\ncF0u+5TmcKyIiIyjfPb9exyYb2ZzzKwMWAbcMWSfO4C/tcCZQKu7b8/xWBERGUd5K2G4e5+ZXQHc\nQ9A19np3X21ml4fbfwDcSdBDaj1Bt9oPDndsvmIVEZGRaeCeiMhR7FC61Wo4qoiI5EQJQ0REcqKE\nISIiOVHCEBGRnBxRjd5m1gJsGuXhjcCuMQynkHQtxedIuQ7QtRSr0V7LbHdvymXHIyphHA4zW5Fr\nT4Fip2spPkfKdYCupViNx7WoSkpERHKihCEiIjlRwhiwvNABjCFdS/E5Uq4DdC3FKu/XojYMERHJ\niUoYIiKSEyUMERHJyVGfMMxsqZmtNbP1ZnZloeM5VGa20cyeNbOnzWxFuK7BzO4zs3Xh88RCx5mJ\nmV1vZjvNbFXauqyxm9lV4ee01szeXJioM8tyLV8ws63hZ/N0eA/75LZivpaZZvaAmT1nZqvN7OPh\n+kh9NsNcR+Q+FzOrMLPHzOyZ8Fq+GK4f38/EU7dWPPoeBFOnvwgcB5QBzwALCh3XIV7DRqBxyLqv\nAFeGy1cC/7fQcWaJ/RzgdGDVSLEDC8LPpxyYE35uJYW+hhGu5QvAP2fYt9ivZRpwerhcC7wQxhyp\nz2aY64jc50Jw++6acLkU+Atw5nh/Jkd7CWMJsN7dN7h7D3AzcFGBYxoLFwE3hss3Am8vYCxZufuD\nwJ4hq7PFfhFws7t3u/tLBPdQWTIugeYgy7VkU+zXst3dnwyX24HngelE7LMZ5jqyKcrrAPBAR/iy\nNHw44/yZHO0JYzqwOe31Fob/H6oYOXC/mT1hZpeF66Z4cOdCgGZgSmFCG5VssUf1s/qYma0Mq6yS\n1QWRuRYzOxY4jeAXbWQ/myHXARH8XMysxMyeBnYC97n7uH8mR3vCOBKc5e6LgAuAj5rZOekbPSif\nRrLvdJRjD32foLpzEbAd+M/ChnNozKwG+BXwCXdvS98Wpc8mw3VE8nNx9/7w3/oMYImZnTxke94/\nk6M9YWwFZqa9nhGuiwx33xo+7wRuJSh27jCzaQDh887CRXjIssUeuc/K3XeE/8gTwI8YqBIo+msx\ns1KCL9mfufst4erIfTaZriPKnwuAu+8DHgCWMs6fydGeMB4H5pvZHDMrA5YBdxQ4ppyZWbWZ1SaX\ngfOBVQTX8Hfhbn8H3F6YCEclW+x3AMvMrNzM5gDzgccKEF/Okv+QQ+8g+GygyK/FzAz4L+B5d/96\n2qZIfTbZriOKn4uZNZlZfbhcCbwJWMN4fyaFbv0v9AN4C0HviReBzxY6nkOM/TiCnhDPAKuT8QOT\ngN8B64D7gYZCx5ol/psIqgR6CepYPzxc7MBnw89pLXBBoePP4Vp+CjwLrAz/AU+LyLWcRVC1sRJ4\nOny8JWqfzTDXEbnPBTgVeCqMeRVwdbh+XD8TTQ0iIiI5OdqrpEREJEdKGCIikhMlDBERyYkShoiI\n5EQJQ0REcqKEIZIDM4uZ2d1mNqvQsYgUirrViuTAzOYCM9z9j4WORaRQlDBERmBm/QQDvZJudvcv\nFyoekUJRwhAZgZl1uHtNoeMQKTS1YYiMkgV3O/yKBXc8fMzM5oXrjzWz34fTZ/8u2e5hZlPM7Nbw\nrmnPmNlrwvW3hdPTr05OUR9OZX2Dma0Kz//Jwl2pSCBe6ABEIqAyvA9B0jXu/vNwudXdTzGzvwW+\nCbwN+A5wo7vfaGYfAr5NcGObbwN/dPd3mFkJkCy1fMjd94STyj1uZr8CjgWmu/vJAMmJ50QKSVVS\nIiPIViVlZhuB17v7hnAa7WZ3n2RmuwgmtOsN129390YzayFoOO8ecp4vEMyaCkGieDPBhHErgDuB\n3wL3ejAdt0jBqEpK5PB4luWcmNm5wBuBV7v7QoIZSSvcfS+wEPgDcDlw3WFHKnKYlDBEDs+7054f\nDZcfIbi3CsB7gT+Fy78D/gFSbRR1QB2w190PmNmJwJnh9kYg5u6/Aj4HnJ7vCxEZiaqkREaQoVvt\n3e5+ZVgl9XOC2+N2A5e4+3ozmw38GGgEWoAPuvvLZjYFWE5wH5N+guTxJHAbQVXUWqAe+AKwNzxH\n8kfdVe5+Vx4vU2REShgioxQmjMXuvqvQsYiMB1VJiYhITlTCEBGRnKiEISIiOVHCEBGRnChhiIhI\nTpQwREQkJ0oYIiKSk/8PmZZT/g2kFfAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ac3af61f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los parámetros han sido aprendidos\n",
      "Precisión de entrenamiento: 1.0\n",
      "Precisión de prueba: 0.875\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**:\n",
    "\n",
    "<table> \n",
    "    <tr> \n",
    "        <td>\n",
    "            **Precisión de  entrenamiento**\n",
    "        </td>\n",
    "        <td>\n",
    "        0.996\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr> \n",
    "        <td>\n",
    "            **Precisión de  prueba**\n",
    "        </td>\n",
    "        <td>\n",
    "        0.733\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bajo la especificación de la tasa de aprendizaje (0.001) y el número de épocas (1500), el algoritmo reconoce los signos con un 73.3% de precicisón. \n",
    "\n",
    "\n",
    "**Anotaciones**:\n",
    "- El modelo parece ajustar bien los datos de entrenamiento. Sin embargo, dada la diferencia entre entrenamiento y predicción, podría intentar mejorar los resultados mediante regularización, ó cambiando los hiper-parámetros. \n",
    "- Visualize la sesión como un bloque de código para entrenar el modelo. Cada vez que ejecuta la sesión con una partición de datos (mini-batches), se entrenan los parámetros. En total la sesión se ha ejecutado un número grande de veces (1500 épocas) hasta que finalmente se obtienen los parámetros \"bien\" entrenados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 - Mejore los resultados\n",
    "\n",
    "Aplicando una técnica de regularización, o alguna otra técnica que usted conozca (también puede probar con cambiar algún hiper-parámetro), intente mejorar los resultados y encuentre un modelo que logre una mayor precisión en prueba. \n",
    "\n",
    "Imprima su resultado (precisión de prueba)  y el método que ha utilizado para conseguirlo. Muestre su código a continuación en una nueva celda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Escriba aquí su nuevo código e imprima el porcentaje de precisión logrado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color='blue'>\n",
    "**Recuerde**:\n",
    "- Tensorflow es una marco de programación muy utilizado en Deep Learning\n",
    "- Hay dos clases de objetos principales en tensorflow: Tensores y Operadores. \n",
    "- Al programar en tensorflow, debe seguir los siguientes pasos:\n",
    "    - Crear un grafo computacional con los tensores (Variables, Placeholders, ...) y Operaciones (tf.matmul, tf.add, ...)\n",
    "    - Crear una sesión\n",
    "    - Inicializar la sesión\n",
    "    - Ejecutar la sesión para ejecutar el grafo\n",
    "- Puede ejecutar el grafo múltiples veces como se ha hecho en model()\n",
    "- La retro-propagación y la optimización se hace automáticamente cuando se ejecuta la sesión sobre el objeto de optimización \"optimizer\"."
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "deep-neural-network",
   "graded_item_id": "BFd89",
   "launcher_item_id": "AH2rK"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
